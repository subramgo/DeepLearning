{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading image files into HDF5 file\n",
    "\n",
    "The data was downloaded from https://www.kaggle.com/c/cifar-10/data\n",
    "Stored in a relative path '../data' to this notebook.\n",
    "\n",
    "The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class.\n",
    "The train folder contains, 50,000 images\n",
    "The test folder contains, 10,000 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "image_path  = '../data/cifar-10/'\n",
    "image_files = '*.png'\n",
    "labels_file = 'trainLabels.csv'\n",
    "\n",
    "\n",
    "# Read the image paths and labels\n",
    "images  = glob.glob(image_path + 'train/' + image_files)\n",
    "labels  = pd.read_csv(image_path + labels_file)\n",
    "\n",
    "# Match the labels for image paths\n",
    "labels_sorted = [labels[labels['id'] == int(os.path.splitext(os.path.basename(img))[0])]['label'].values[0] for img in images]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of images in train folder {}\".format(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code label string to integers\n",
    "labels_coded = pd.get_dummies(labels_sorted)\n",
    "labels_coded = labels_coded.values.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## Shuffle the data set\n",
    "sh = list(zip(images, labels_coded))\n",
    "shuffle(sh)\n",
    "imgs, lbls = zip(*sh)\n",
    "\n",
    "## Create train data set\n",
    "train_size = 0.95\n",
    "train_images = imgs[0:int(train_size * len(imgs))]\n",
    "train_labels = lbls[0:int(train_size * len(lbls))]\n",
    "\n",
    "## create test data set\n",
    "test_images = imgs[int(train_size * len(imgs)):]\n",
    "test_labels = lbls[int(train_size * len(lbls)):]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our training set size {}\".format(len(train_images)))\n",
    "print(\"Our test set size {}\".format(len(test_images)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Image width x height is 32 x 32, with 3 channels\n",
    "train_shape = (len(train_images), 32, 32, 3)\n",
    "test_shape  = (len(test_images), 32, 32, 3)\n",
    "\n",
    "\n",
    "hdf5_path = '../data/cifar-10/hdf5/cifar_10.h5'\n",
    "\n",
    "# Open a hdf5 file and create earray\n",
    "hdf5_file = h5py.File(hdf5_path, mode = 'w')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_images\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_images\", test_shape, np.int8)\n",
    "\n",
    "\n",
    "hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_labels),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_labels),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "\n",
    "## Load train image\n",
    "for i in range(len(train_images)):\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Train data {}/{}\".format(i, len(train_images)))\n",
    "    \n",
    "    path = train_images[i]\n",
    "    image = cv2.imread(path)\n",
    "    hdf5_file[\"train_images\"][i, ...] = image[None]\n",
    "    mean += image / float(len(train_labels))\n",
    "\n",
    "## Load test image\n",
    "for i in range(len(test_images)):\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Test data {}/{}\".format(i, len(test_images)))\n",
    "    \n",
    "    path = train_images[i]\n",
    "    image = cv2.imread(path)\n",
    "    hdf5_file[\"test_images\"][i, ...] = image[None]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access HDF5 File for Processing\n",
    " * Using Adience data\n",
    " * Feed into a `keras.preprocessing.image.ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hdf5_path = '../../data/Adience/hdf5/adience.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "## This is an awkward way to access the groups & data sets from an h5py file. Is there a more \"proper\" way?\n",
    "train_images,train_labels,train_mean = f.items()\n",
    "train_images = train_images[1]\n",
    "train_labels = train_labels[1]\n",
    "train_mean   = train_mean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator( featurewise_center=False,\n",
    "                                samplewise_center=True,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_whitening=False,\n",
    "                                zca_epsilon=1e-6,\n",
    "                                rotation_range=0.,\n",
    "                                width_shift_range=0.,\n",
    "                                height_shift_range=0.,\n",
    "                                shear_range=0.,\n",
    "                                zoom_range=0.,\n",
    "                                channel_shift_range=0.,\n",
    "                                fill_mode='nearest',\n",
    "                                cval=0.,\n",
    "                                horizontal_flip=False,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=None,\n",
    "                                preprocessing_function=None,\n",
    "                                data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not useful?!\n",
    "generator.fit(train_images[:50])    # test first 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen = generator.flow(train_images[:50],train_labels[:50]) # test first 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = _gen.next()\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 256x256x3 --?!?-> 2x32x32\n",
    "len(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
