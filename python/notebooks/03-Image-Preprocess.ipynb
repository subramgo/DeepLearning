{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading image files into HDF5 file\n",
    "\n",
    "The data was downloaded from https://www.kaggle.com/c/cifar-10/data\n",
    "Stored in a relative path '../data' to this notebook.\n",
    "\n",
    "The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class.\n",
    "The train folder contains, 50,000 images\n",
    "The test folder contains, 10,000 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "image_path  = '../data/cifar-10/'\n",
    "image_files = '*.png'\n",
    "labels_file = 'trainLabels.csv'\n",
    "\n",
    "\n",
    "# Read the image paths and labels\n",
    "images  = glob.glob(image_path + 'train/' + image_files)\n",
    "labels  = pd.read_csv(image_path + labels_file)\n",
    "\n",
    "# Match the labels for image paths\n",
    "labels_sorted = [labels[labels['id'] == int(os.path.splitext(os.path.basename(img))[0])]['label'].values[0] for img in images]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images in train folder 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"No of images in train folder {}\".format(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code label string to integers\n",
    "labels_coded = pd.get_dummies(labels_sorted)\n",
    "labels_coded = labels_coded.values.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## Shuffle the data set\n",
    "sh = list(zip(images, labels_coded))\n",
    "shuffle(sh)\n",
    "imgs, lbls = zip(*sh)\n",
    "\n",
    "## Create train data set\n",
    "train_size = 0.95\n",
    "train_images = imgs[0:int(train_size * len(imgs))]\n",
    "train_labels = lbls[0:int(train_size * len(lbls))]\n",
    "\n",
    "## create test data set\n",
    "test_images = imgs[int(train_size * len(imgs)):]\n",
    "test_labels = lbls[int(train_size * len(lbls)):]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set size 47500\n",
      "Our test set size 2500\n"
     ]
    }
   ],
   "source": [
    "print(\"Our training set size {}\".format(len(train_images)))\n",
    "print(\"Our test set size {}\".format(len(test_images)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Image width x height is 32 x 32, with 3 channels\n",
    "train_shape = (len(train_images), 32, 32, 3)\n",
    "test_shape  = (len(test_images), 32, 32, 3)\n",
    "\n",
    "\n",
    "hdf5_path = '../data/cifar-10/hdf5/cifar_10.h5'\n",
    "\n",
    "# Open a hdf5 file and create earray\n",
    "hdf5_file = h5py.File(hdf5_path, mode = 'w')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_images\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_images\", test_shape, np.int8)\n",
    "\n",
    "\n",
    "hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_labels),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_labels),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 1000/47500\n",
      "Train data 2000/47500\n",
      "Train data 3000/47500\n",
      "Train data 4000/47500\n",
      "Train data 5000/47500\n",
      "Train data 6000/47500\n",
      "Train data 7000/47500\n",
      "Train data 8000/47500\n",
      "Train data 9000/47500\n",
      "Train data 10000/47500\n",
      "Train data 11000/47500\n",
      "Train data 12000/47500\n",
      "Train data 13000/47500\n",
      "Train data 14000/47500\n",
      "Train data 15000/47500\n",
      "Train data 16000/47500\n",
      "Train data 17000/47500\n",
      "Train data 18000/47500\n",
      "Train data 19000/47500\n",
      "Train data 20000/47500\n",
      "Train data 21000/47500\n",
      "Train data 22000/47500\n",
      "Train data 23000/47500\n",
      "Train data 24000/47500\n",
      "Train data 25000/47500\n",
      "Train data 26000/47500\n",
      "Train data 27000/47500\n",
      "Train data 28000/47500\n",
      "Train data 29000/47500\n",
      "Train data 30000/47500\n",
      "Train data 31000/47500\n",
      "Train data 32000/47500\n",
      "Train data 33000/47500\n",
      "Train data 34000/47500\n",
      "Train data 35000/47500\n",
      "Train data 36000/47500\n",
      "Train data 37000/47500\n",
      "Train data 38000/47500\n",
      "Train data 39000/47500\n",
      "Train data 40000/47500\n",
      "Train data 41000/47500\n",
      "Train data 42000/47500\n",
      "Train data 43000/47500\n",
      "Train data 44000/47500\n",
      "Train data 45000/47500\n",
      "Train data 46000/47500\n",
      "Train data 47000/47500\n",
      "Train data 1000/2500\n",
      "Train data 2000/2500\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "\n",
    "## Load train image\n",
    "for i in range(len(train_images)):\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Train data {}/{}\".format(i, len(train_images)))\n",
    "    \n",
    "    path = train_images[i]\n",
    "    image = cv2.imread(path)\n",
    "    hdf5_file[\"train_images\"][i, ...] = image[None]\n",
    "    mean += image / float(len(train_labels))\n",
    "\n",
    "## Load test image\n",
    "for i in range(len(test_images)):\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Test data {}/{}\".format(i, len(test_images)))\n",
    "    \n",
    "    path = train_images[i]\n",
    "    image = cv2.imread(path)\n",
    "    hdf5_file[\"test_images\"][i, ...] = image[None]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file[\"train_mean\"][...] = mean\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
